{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritish/prog/ML/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets as Datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "mnist_train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "mnist_test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "training_set = Datasets.MNIST(root='../../autoencoder', download=False, train=True, transform=mnist_train_transforms)\n",
    "validation_set = Datasets.MNIST(root='../../autoencoder', download=False, train=False, transform=mnist_test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLin(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "class DecoderLin(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 28*28),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        return x\n",
    "    \n",
    "class CAE_Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderLin()\n",
    "        self.decoder = DecoderLin()\n",
    "\n",
    "    def forward(self, x):\n",
    "        e_out = self.encoder(x)\n",
    "        d_out = self.decoder(e_out)\n",
    "        return e_out, d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "class DecoderConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=4, stride=2, padding=3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        return x.view(-1, 1, 28, 28)\n",
    "    \n",
    "class CAE_Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = EncoderConv()\n",
    "        self.decoder = DecoderConv()\n",
    "\n",
    "    def forward(self, x):\n",
    "        e_out = self.encoder(x)\n",
    "        d_out = self.decoder(e_out)\n",
    "        return e_out, d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/58249160/how-to-implement-contractive-autoencoder-in-pytorch\n",
    "\n",
    "# Contractive loss function to enforce contraction of representations\n",
    "def loss_function(e_out, d_out, inp, L=1e-4):\n",
    "    criterion = nn.MSELoss()\n",
    "    loss1 = criterion(d_out, inp)\n",
    "\n",
    "    # Calculate jacobian of encoder output wrt input\n",
    "    e_out.backward(torch.ones_like(e_out), retain_graph=True)\n",
    "\n",
    "    # Frobenius norm of jacobian\n",
    "    loss2 = torch.sqrt(torch.sum(torch.pow(inp.grad, 2)))\n",
    "    \n",
    "    # Total loss\n",
    "    return loss1 + L*loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CAE_Conv().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
    "train_loader = DataLoader(training_set, batch_size=256, shuffle=True, num_workers=16, pin_memory=True)\n",
    "val_loader = DataLoader(validation_set, batch_size=256, shuffle=True, num_workers=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:01<00:00, 211.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.30072586530066553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:01<00:00, 216.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.30905027630481313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:01<00:00, 223.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4293945841332699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, (imgs, _) in enumerate(tqdm(train_loader)):\n",
    "        imgs = imgs.to(device)\n",
    "        \n",
    "        # Required to calculate jacobian of encoder output wrt input\n",
    "        imgs.requires_grad = True\n",
    "\n",
    "        # Forward pass\n",
    "        e_out, d_out = model(imgs)\n",
    "        loss = loss_function(e_out, d_out, imgs, L=1e-4)\n",
    "\n",
    "        # Backpropogate and update weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Zero out gradients of input\n",
    "        imgs.grad.data.zero_()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Train Loss: {train_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing the model\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    img, _ = next(iter(val_loader))\n",
    "    img = img.to(device)\n",
    "    _, d_out = model(img)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(img[0].cpu().numpy().squeeze(), cmap='gray')\n",
    "    ax[1].imshow(d_out[0].cpu().numpy().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
